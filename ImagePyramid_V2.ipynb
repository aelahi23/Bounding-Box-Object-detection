{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImagePyramid_V1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "id": "erU1x-UahukE",
        "outputId": "1b2f1508-4dbe-4a64-c34b-fa16045acbdf"
      },
      "source": [
        "import pandas as pd \n",
        "import os\n",
        "import numpy as np \n",
        "import cv2 \n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import utils\n",
        "from tensorflow.keras.applications.resnet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from keras.preprocessing import image \n",
        "from tensorflow import shape\n",
        "#from imutils.object_detection import non_max_suppression\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from skimage.segmentation import mark_boundaries\n",
        "from google.colab.patches import cv2_imshow # I used this becuase imshow from cv2 cause colab to crash ¯\\_(ツ)_/¯\n",
        "import imutils\n",
        "import time\n",
        "\n",
        "'''\n",
        "accuracy of my detections is dependent \n",
        "on image pyramid scale, \n",
        "sliding window step, and ROI size\n",
        "'''\n",
        "\n",
        "def pyramid(image, scale=1.5, minSize=(256, 256)): # Default minsize used to limit prymid otherwise it could be infitley small\n",
        "    # yield the original image\n",
        "    yield image\n",
        "    # keep looping over the pyramid\n",
        "    while True:\n",
        "        # compute the new dimensions of the image and resize it\n",
        "        w = int(image.shape[1]/scale)\n",
        "        image = imutils.resize(image, width=w)\n",
        "        # if the resized image does not meet the supplied minimum\n",
        "        # size, then stop constructing the pyramid\n",
        "        if image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
        "            break\n",
        "        # yield the next image in the pyramid\n",
        "    print(\"Reszied\")\n",
        "    print(\"Size: \",image.shape)\n",
        "    cv2_imshow(image)\n",
        "    yield image\n",
        "\n",
        "def sliding_window(image, stepSize, windowSize = (100,100)):\n",
        "    # slide a window across the image\n",
        "    for y in range(0, image.shape[0], stepSize):\n",
        "        for x in range(0, image.shape[1], stepSize):\n",
        "            # yield the current window\n",
        "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
        "\n",
        "# load the image and Classifer model and define the window width and height\n",
        "model_path = \"/content/drive/MyDrive/VGG16_V1\" #61% accuracy\n",
        "model = tf.keras.models.load_model(model_path) \n",
        "WIDTH = 64 # will use this to resize all camera images and test data images to one size\n",
        "Orgimage = cv2.imread(\"/content/drive/MyDrive/Colab Notebooks/Tests/NsdC_t14-053.png\")\n",
        "Orgimage = imutils.resize(Orgimage, width=WIDTH)\n",
        "#Orgimage = cv2.GaussianBlur(Orgimage,(7,7),0)\n",
        "\n",
        "minS = (32,32)\n",
        "ROI_size = (16,16) #  the size of the window which is the size of the ROI\n",
        "\n",
        "minConf = 0.9999 # My minimum probability threshold\n",
        "pry_scale = 1.5\n",
        "win_step = 8 # step size for window need to balance between time and accuracy \n",
        "\n",
        "INPUT_SIZE = (128,128)\n",
        "(H, W) = Orgimage.shape[:2]\n",
        "print ('H,W: ', H,W)\n",
        "\n",
        "pyramidImg = pyramid(Orgimage, scale=pry_scale, minSize=minS)\n",
        "rois = [] # Holds the regions of interest (ROIs) generated from pyramid + sliding window output\n",
        "locs = [] #  Stores the (x, y)-coordinates of where the ROI was in the original image\n",
        "start = time.time()\n",
        "# loop over the image pyramid\n",
        "#First get the scale factor for image, than loop sliding window on the image\n",
        "\n",
        "for image in pyramidImg:\n",
        "    # determine the scale factor between the *original* image\n",
        "    # dimensions and the *current* layer of the pyramid\n",
        "    scale = W / float(image.shape[1])\n",
        "    cv2_imshow(image)\n",
        "    # for each layer of the image pyramid, loop over the sliding\n",
        "    # window locations\n",
        "    for (x, y, roiOrig) in sliding_window(image, win_step, ROI_size):\n",
        "        # scale the (x, y)-coordinates of the ROI with respect to the\n",
        "        # *original* image dimensions\n",
        "        x = int(x * scale)\n",
        "        y = int(y * scale)\n",
        "        w = int(ROI_size[0] * scale)\n",
        "        h = int(ROI_size[1] * scale)\n",
        "        # take the ROI and preprocess it so we can later classify\n",
        "        # the region using Keras/TensorFlow\n",
        "        roi = cv2.resize(roiOrig, INPUT_SIZE)\n",
        "        roi = img_to_array(roi)\n",
        "        roi = preprocess_input(roi)\n",
        "        # update our list of ROIs and associated coordinates\n",
        "        rois.append(roi)\n",
        "        locs.append((x, y, x + w, y + h))\n",
        "        '''\n",
        "        #Uncomment this section is to visulaise my ROI \n",
        "        clone = Orgimage.copy()\n",
        "        cv2.rectangle(clone, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "        # show the visualization and current ROI\n",
        "        clone = Orgimage.copy()\n",
        "        print(\"Visualization\")\n",
        "        cv2_imshow(clone)\n",
        "        print(\"ROI\")\n",
        "        cv2_imshow(roiOrig)'''\n",
        "        \n",
        "        '''\n",
        "        clone2 = image.copy()\n",
        "        cv2.rectangle(clone2, (x, y), (x + winW, y + winH), (0, 255, 0), 2)\n",
        "        cv2_imshow(clone2)\n",
        "        cv2.waitKey(1)\n",
        "        time.sleep(0.025)\n",
        "        cv2.waitKey(0)'''\n",
        "\n",
        "end = time.time()\n",
        "# end of Pyramid and sliding window\n",
        "\n",
        "print(\"[INFO] looping over pyramid/windows took {:.5f} seconds\".format(end - start))\n",
        "# convert the ROIs to a NumPy array\n",
        "rois = np.array(rois, dtype=\"float32\")\n",
        "# classify each of the proposal ROIs using ResNet and then show how\n",
        "# long the classifications took\n",
        "print(\"[INFO] classifying ROIs...\")\n",
        "start = time.time()\n",
        "preds = model.predict(rois)\n",
        "end = time.time()\n",
        "print(\"[INFO] classifying ROIs took {:.5f} seconds\".format(end - start))\n",
        "\n",
        "# decode the predictions and initialize a dictionary which maps class\n",
        "# labels (keys) to any ROIs associated with that label (values)\n",
        "#print(\"Prediction \",preds) \n",
        "labels  = {0: 'NsdC', 1: 'PacC', 2: 'RfeC', 3: 'WT'}\n",
        "Category_index = preds.argmax(axis=-1) # Just need the top predcition of that ROI\n",
        "maxProb = preds.max(axis=-1)\n",
        "#print(\"Category_index \",Category_index) \n",
        "#print(\"Max probability \",maxProb)\n",
        "\n",
        "LabelBoxProb1 = []\n",
        "LabelBoxProb = []\n",
        "boxes = []\n",
        "boxes3 = []\n",
        "probs =[]\n",
        "probs3 =[]\n",
        "names = []\n",
        "names3 = []\n",
        "counter = 0\n",
        "#Filter out boxes with predcitons below threshold set in minConf\n",
        "for (i, p) in enumerate(Category_index):\n",
        "\t# grab the prediction information for the current ROI\n",
        "    prob = maxProb[i]\n",
        "    label = Category_index[i]\n",
        "    # filter out weak detections by ensuring the predicted probability\n",
        "\t# is greater than the minimum probability\n",
        "    if prob >= minConf :\n",
        "        counter = counter + 1\n",
        "        # grab the bounding box associated with the prediction and\n",
        "        # convert the coordinates\n",
        "        box = locs[i] #.append((locs[i],labels.get(label)))\n",
        "        # grab the list of predictions for the label and add the\n",
        "        # bounding box and probability to the list\n",
        "        L = [labels.get(label,[])]\n",
        "        L.append(box)\n",
        "        L.append(prob)\n",
        "        LabelBoxProb.append(L)\n",
        "        #labels[label] = L\n",
        "print(\"Size of LabelBoxProb \",  LabelBoxProb[0][0])\n",
        "# loop over the labels for each of detected objects in the image\n",
        "\n",
        "clone = Orgimage.copy()\n",
        "# loop over all bounding boxes for the current label\n",
        "for (name, box, prob) in LabelBoxProb:\n",
        "    # draw the bounding box on the image\n",
        "    boxes.append(box)\n",
        "    probs.append(prob)\n",
        "    names.append(name) #<----------------- use this to rpelace label in box labelling\n",
        "    (startX, startY, endX, endY) = box\n",
        "    cv2.rectangle(clone, (startX, startY), (endX, endY),(0, 255, 0), 2)\n",
        "\n",
        "# show the results *before* applying non-maxima suppression, then\n",
        "# clone the image again so we can display the results *after*\n",
        "# applying non-maxima suppression\n",
        "print(\"after scanning\")\n",
        "cv2_imshow(clone)\n",
        "clone = Orgimage.copy()\n",
        "\n",
        "boxes1 = np.array(boxes, dtype=np.int64)\n",
        "probs1 = np.array(probs, dtype=np.float32)\n",
        "boxes2= tf.image.non_max_suppression(boxes1, probs1, 100,\n",
        "                          iou_threshold=0.01,\n",
        "                          score_threshold=float('-inf'), \n",
        "                          name=None)\n",
        "#boxes2 = non_max_suppression(boxes1, probs1)\n",
        "c=0\n",
        "\n",
        "\n",
        "for j in range(len(boxes2)):\n",
        "  LabelBoxProb1.append(LabelBoxProb[boxes2[j]])\n",
        "  \n",
        "totalNumberOFSpores = len(LabelBoxProb1)\n",
        "\n",
        "for (fungi,box3,prob3) in LabelBoxProb1:\n",
        "  # draw the bounding box on the image\n",
        "  (startX, startY, endX, endY) = box3\n",
        "  cv2.rectangle(clone, (startX, startY), (endX, endY),(0, 255, 0), 2)\n",
        "  y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "  cv2.putText(clone,str(fungi) +\"  \" +str(prob3), (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
        "print(\"After\")\n",
        "cv2_imshow(clone)\n",
        "cv2.waitKey(0)\n",
        "'''\n",
        "for (startX, startY, endX, endY) in boxes2:\n",
        "    \n",
        "    # draw the bounding box and label on the image\n",
        "    cv2.rectangle(clone, (startX, startY), (endX, endY),(0, 255, 0), 2)\n",
        "    y = startY - 10 if startY - 10 > 10 else startY + 10\n",
        "    cv2.putText(clone, labels.get(label,[])+\" \"+str(probs1[c]), (startX, y),\n",
        "  cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 255, 0), 2)\n",
        "    c=c+1'''\n",
        "# show the output after apply non-maxima suppression\n",
        "\n",
        "\n",
        "#Now to pply NOn Maximum suppersion\n",
        "# extract the bounding boxes and associated prediction\n",
        "\n",
        "\n",
        "# loop over all bounding boxes that were kept after applying\n",
        "# non-maxima suppression\n",
        "\n",
        "print(\"Done!\")\n",
        "print(\"Spore Count \", totalNumberOFSpores)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "H,W:  64 64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAKdklEQVR4nIVaW3rbvA4EKepiO22/Zv9b6aLaJNaV4nmYaDIClf/oIXVligAGgyFIOfz588fMSilN05RS8BlXCCGEgDs5523bQghN0zRNE2PEfY7hhZv7vuN+CCHnjJsY8Pb2ZmYvLy8pJd4MIZRS9n3n51JKjDHGiNn2fcedt7e3YRjatsWwhH+apoFJuh5j1DBijBphzhmW6LEGk3PG55yzOvH+/p5zvt1uwzCYGS2aGRBhzAocTcQYp2lKKeEOHk8AgOMwF78mliEEPsnZdTwcohNqFeB9fHyklH7+/AkgAKdCAFuKIHGhUbCA0ZZSPgOgl7gwO75qmkYdgq9KGz7C/yKf5M80TcuydF03DANA5XjHGSUkDZHS67qCvU3TINoYY4LrDJcTMSTMAkuaZZrhSIbNeczs4+Pjfr8/Ho9pmpxz9YUMKCJ8ZNu2cRzv9zvG8KukKJL3NKCWdF7WKMcgQmXRNE3zPL++vo7jWErpuk7J7cqGJjSTmpl5nh+PxziOqB+O/KIQwVNa869Cws+ksp0rz8yez2dK6ffv3+M4dl2HUiY09MxECWpykvpQITPr+x7adQqgiMaxktQb0sZFpZY0zpxzznkYhnmeb7dbzTp8UMj4VZ0WM1uWpe97RZkjk0apWDIVSlA7X+Gs4nR0nuf7/b6uK9LtnNOAHUB1qKWUbdtKKcMwjOOYUnJhRxY1/joDlx6jWly0qGY8sq5rKUUFuxyLlHOXtadfuSJcluV2u43jCA/VkJmldV1TSqCyKoBLoipMnQHWDBjYtm0pBYulnetKnWMAdq4KnXld177vobyEmN5+BgB6QCXqLDtSaQzhkFcd8Hw+27bdto0B4Koz4DLsTPDZvu9BHpMF9ysDt9ttWZZt22KMzqQas6vLLb0hhJwzqO9IqFXuYvhvnWiaZlkWzKxTUccTstN1HcYh0CDd2KWj+gGkxDVN08vLC9SazKnBZkHXZeZMbNsGddGcFGkUUtu2+74j44hBewc16WxALtV7O+qbFVxrce1iXW90HfoDQ23bxhghDyz9fd8/zSAM6DdKMJwXRW1aTLRFJbnrOjMD/E7QOE+QrsRFggtoommDYwgm54xU6MwB3SgFMaWEcTX1td1law6wc85IGp5NKcGqkwFtnvFhXddt25qmSSnt+z7PM0oRF7SRewmYoMxw8qT8jjHO87yua9d1l5m9XB8wAwyklGCYxthOOy5hhUIFTtPEbNBdTMsFR7FXu0ljQrO6rqtC6FLh1FprHTS1s/io8jhRAkzIA8KG0iOZ3PpdKjgrITmYu66bpgkz1mWn0HIWRGuVOoGyZE4dBnY2y7Kg6LlaObDrtY8m1nX96uzIohhjzhky4i4Xku4i1G98pfsETaDWA7bacJrbXLuSL0KuG5UYY1LzRHSeZzOjltOzcFy1MioQZC2d1k2giRxBFvu+Z5vASQhNOfZMCiJLJbnvYAlr8zRNaOUVdc7O/9q5adW+SF3R/QDn6fu+7/vLMw56r+g4sEopSauEJodhWJYF29m2bbky2PerkruvTFVX3GDNkp3pbpWKONQK9wM1YKgElFcRpVdsNAaluwuVd+pqNiEnBzsUXNjh2G/FGLdtez6fCYrLMNSzpmmwNhc59mIGHX9qpVNEdCeuI7UHserSSJRdTdPM81xKud/vifl1DOGBFPLA/VqdBNdlaL1qPTgXHcUvnb40F0L4+PgopWDRTFQ9NwX/Ysu2bVvf98oKuqvqoQwOx9GNVgIdqiG/dF2PF3CN4xhCSCmh9UpQfSeRnAJ5mOcZdez8Y4RMkbIrHB1BkUOUIudIGlWQwwQXgNrC4VLbtiklsPorA1oGdq4njFFCM4ZSyrZtjjkYiYNRnrqSY6oHmm09jVXy0AGo4jAMsIWAE1GB2pD6nBrdIvxG0JQ/ZRHssVjRF7C7dMXqkNbMaxgKZYzx79+/aHW1wJKm2MzWdeWqzhjQaTn1AJBEKFSLCQuMDjGfKhjOXVfQDPvt7S2E8Hg89KuCw13QwLmrrqBFRalg72/H/pqV6ggAyF3VIsNamiS60wCWSjm0fxgGbc8g8THGBP/A43J1uMLZsTajz1N3EZgrDJANiVJJcLniV1rNRRST1gkr/sJhM0saK3HV7U85OrwY4/P5XJbl8XjwgBKDL1fZnPM4jtM0/fjx43a7EX4mRLVLa1pr1FUzx3Bh/fQjnJchYq+4Nk2DMxi8qmALqfwupczzzKU95/z6+vrv3z/sku284JAeJletoZoWLRvoRGLhm6wvRCXK2xrwBL5ix4NvcXYQQliWxcwgFNjUruv6/v7+eDwAP189leP1DMmmYF9iT+/tLLtJMaZyh/NeEZzDGR68N7NlWXCHLTdmREHDraZpfv36RR5SoMtx2fnETu+rUulFguG/iZPiQEFXPk6H2uVmre97sBCVgAzgv2AdXihpE06xMtF1hZNO6zrtLvWKSUg1PHXo2F+DLRBcvGgADBRWJgfnfNgoOsGhyBZZcVWL1GMnWSb7VUb7dX7GofqYnV8LNE3TdR33+y5U5gEbRW1AtPgcqI45NWecFZWNwlZCSe/+RjkWZ4WoK07LUb6oEDSMShvXUGjwdu5KNG+aLvf41wOXFAqyFIBIGlioLnJmGAYcEnJJMWkiguw39PqOTpzceRiwpbwcrTBr/7if308GUeggh+CUUZQyAWM7AFWoAf6OSHopZU5dtHsYVejiVhtFXhzZ0YkwS/hKz5M5A7azrlniB0dORwoH9KmITVZiR1CloFVvDNQkjfGdSinFHc84fjofarsuJCIY+FsJnYV3sHByaLjqeOuL4oMeKaXEVpfuYjerTzk2uglLpbmM4XQAGs7yoqDW9/WRGlrc7/seTcclRjqJm8GqbDgIeH0dr2sNXPLeweCs1p6Fo9VxjgZRtiJLtX1DRReYCzhxA1CXTo2Kkws1zzHaI2ib7QrGWanTW3t8iVFiuO5rp5XqmVMtnUGLUiunFspa04JcOnOpVjGdMCn8dYg6O0E1YXldMBqeO9B1YNUSVFfwd0Tgh1R/odtFVxt2VIid+UoU4vkYvZxXgEuY/rvSLpVDJ/nSMjrhdgK0rdlUmGsX2RLrMqcAa1Uo/FYVw6UolaM/KPzJmZ15bEIbF2FdG6paLpnOJ45xhsi37+rEPa4nOqcTlBrgOmUcr4nmU5Qd/IbEpHd34dWH0k4V7HjLxqwqIjy0/NoTa6voaHOZjRpUvak/7HGcdl468vxfCqm3hfuBIq84XSqc67z0gM0BaUcDu8vPKDWZroQcA+ticNWib+M/a8CpB6ZzsfJ5rV31Q6uonIXfnQjVS4pmyeXW1b2bOdn5BZGbt04rb4bzmkCrVJ5SrQN1MhUU95U+WAPHM7/kdsDKy9pv9cC9GQlnCQ7nn+E6FGP1xtLBpCnS007awpFCwVvKIu+CFMVy3qfqX2WFwqMkZhuncGBbzI2bCan0WbbQTls1DwAr7fKDABM6qWFd2vSNotrGxXLUQzhG6KBRqdjPLyrrE0idRG0lbhrLcdRKh5TNCpJmWf3DPDj8ci+XTIjuXjEF0Rx6Eq6EiP6o6f8B5BLH73eDdK0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F370E48CF60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Reszied\n",
            "Size:  (28, 28, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACJklEQVR4nIVVUbbsIAgDxM7+FzQbqy3ej3Ry83TueXz0tFYChKD+fr/tY3NOM7uuKyIiwt3dnevufl3Xfd+ZmZkm5u5zzjGGmT3/5pxwjog5Z2biE0/6XNdVVcdxRIRtNuesKgAGEDWjPceqOs/T3XvvfyHe9+3u8A0swVlJYI4kpLXWWtsRidBaQ8ioqq+bNNmqaq2BBAYjOSgFbcCGvO+7qnrvO/FalxbBvxqmqpBfRGTvHT1laQp3XZeZZSbqInpVuXtVoQ7AsbJ098wcY6DAJT6I5y/qBOoBFqhklx5QGASoJGA3ckRqJgoZY0B87A8SqqpkRtT83oedazPrvWsnUMScMyIeUOR4nmfvHeRih1atygPcsoGdCFaUma21+77ZCk1Qu2T/StvFxhhVFfNjIBENXcaBoDTlhGo5zzMieu8BTSACOshWmIwpw1ChCzpOBlAXYIE+kBdqV5SqwjZNX/WQma/XC6p6JKXxI4IdKzF31yOKLkrR03aWrBOCpHgwttbQbvVc9KAxHvWy4yj8OA4gwhPBlGXNd1HFr05hFL/622c0juNQPepJtsg5lm6SDZUhYlDCOGWWo0tXfjNVdvYZVU5ba3r06exiMcnmIhG1RZL/fQ//XHn0XERjItg93teooQpn1rqbp6Rtg6TvDOm4+GiLngm3XIuMyvdlQy4jsYhm+aWffC7yMrPcr7CdEPujIXvU34n6Omo74tcKqCrF+QH9z2S1lYsSdgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F36FD485390>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACJklEQVR4nIVVUbbsIAgDxM7+FzQbqy3ej3Ry83TueXz0tFYChKD+fr/tY3NOM7uuKyIiwt3dnevufl3Xfd+ZmZkm5u5zzjGGmT3/5pxwjog5Z2biE0/6XNdVVcdxRIRtNuesKgAGEDWjPceqOs/T3XvvfyHe9+3u8A0swVlJYI4kpLXWWtsRidBaQ8ioqq+bNNmqaq2BBAYjOSgFbcCGvO+7qnrvO/FalxbBvxqmqpBfRGTvHT1laQp3XZeZZSbqInpVuXtVoQ7AsbJ098wcY6DAJT6I5y/qBOoBFqhklx5QGASoJGA3ckRqJgoZY0B87A8SqqpkRtT83oedazPrvWsnUMScMyIeUOR4nmfvHeRih1atygPcsoGdCFaUma21+77ZCk1Qu2T/StvFxhhVFfNjIBENXcaBoDTlhGo5zzMieu8BTSACOshWmIwpw1ChCzpOBlAXYIE+kBdqV5SqwjZNX/WQma/XC6p6JKXxI4IdKzF31yOKLkrR03aWrBOCpHgwttbQbvVc9KAxHvWy4yj8OA4gwhPBlGXNd1HFr05hFL/622c0juNQPepJtsg5lm6SDZUhYlDCOGWWo0tXfjNVdvYZVU5ba3r06exiMcnmIhG1RZL/fQ//XHn0XERjItg93teooQpn1rqbp6Rtg6TvDOm4+GiLngm3XIuMyvdlQy4jsYhm+aWffC7yMrPcr7CdEPujIXvU34n6Omo74tcKqCrF+QH9z2S1lYsSdgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28 at 0x7F370E48CF60>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[INFO] looping over pyramid/windows took 0.02634 seconds\n",
            "[INFO] classifying ROIs...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-5c92aa392e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] classifying ROIs...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] classifying ROIs took {:.5f} seconds\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer sequential: expected shape=(None, 66, 66, 3), found shape=(None, 128, 128, 3)\n"
          ]
        }
      ]
    }
  ]
}